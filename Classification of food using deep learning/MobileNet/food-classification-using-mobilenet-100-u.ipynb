{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:10.730741Z",
     "iopub.status.busy": "2024-02-12T12:08:10.730407Z",
     "iopub.status.idle": "2024-02-12T12:08:10.735748Z",
     "shell.execute_reply": "2024-02-12T12:08:10.734472Z",
     "shell.execute_reply.started": "2024-02-12T12:08:10.730711Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:10.737391Z",
     "iopub.status.busy": "2024-02-12T12:08:10.737123Z",
     "iopub.status.idle": "2024-02-12T12:08:10.944518Z",
     "shell.execute_reply": "2024-02-12T12:08:10.943807Z",
     "shell.execute_reply.started": "2024-02-12T12:08:10.737365Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import models\n",
    "from PIL import Image \n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>IMAGE PROCESSSING</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:10.946458Z",
     "iopub.status.busy": "2024-02-12T12:08:10.946105Z",
     "iopub.status.idle": "2024-02-12T12:08:10.981086Z",
     "shell.execute_reply": "2024-02-12T12:08:10.980278Z",
     "shell.execute_reply.started": "2024-02-12T12:08:10.946421Z"
    }
   },
   "outputs": [],
   "source": [
    "img = plt.imread('/Users/tushar/Documents/FINAL YEAR PROJECT/data/train/pizza/1008104.jpg.jpg')\n",
    "dims = np.shape(img)\n",
    "matrix = np.reshape(img, (dims[0] * dims[1], dims[2]))\n",
    "print(np.shape(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:10.982699Z",
     "iopub.status.busy": "2024-02-12T12:08:10.982425Z",
     "iopub.status.idle": "2024-02-12T12:08:11.208985Z",
     "shell.execute_reply": "2024-02-12T12:08:11.208166Z",
     "shell.execute_reply.started": "2024-02-12T12:08:10.982673Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "print(\"Image shape -> \",dims[:2])\n",
    "print(\"Color channels -> \",dims[2])\n",
    "print(\"Min color depth : {}, Max color depth {}\".format(np.min(img),np.max(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:11.210448Z",
     "iopub.status.busy": "2024-02-12T12:08:11.210170Z",
     "iopub.status.idle": "2024-02-12T12:08:27.152769Z",
     "shell.execute_reply": "2024-02-12T12:08:27.151928Z",
     "shell.execute_reply.started": "2024-02-12T12:08:11.210420Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "n_vals=[2,4,6,8]\n",
    "plt.figure(1, figsize=(12, 8))\n",
    "\n",
    "for subplot,n in enumerate(n_vals):\n",
    "    kmeans=cluster.KMeans(n)\n",
    "    clustered = kmeans.fit_predict(matrix)\n",
    "    dims = np.shape(img)\n",
    "    clustered_img = np.reshape(clustered, (dims[0], dims[1]))\n",
    "    plt.subplot(2,2, subplot+1)\n",
    "    plt.title(\"n = {}\".format(n), pad = 10,size=18)\n",
    "    plt.imshow(clustered_img)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:27.154462Z",
     "iopub.status.busy": "2024-02-12T12:08:27.154134Z",
     "iopub.status.idle": "2024-02-12T12:08:27.449154Z",
     "shell.execute_reply": "2024-02-12T12:08:27.448296Z",
     "shell.execute_reply.started": "2024-02-12T12:08:27.154433Z"
    }
   },
   "outputs": [],
   "source": [
    "bnorm = np.zeros_like(matrix, dtype=np.float32)\n",
    "max_range = np.max(matrix, axis=1)\n",
    "bnorm = matrix / np.vstack((max_range, max_range, max_range)).T\n",
    "bnorm_img = np.reshape(bnorm, (dims[0],dims[1],dims[2]))\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.imshow(bnorm_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2> Sobel filter is a basic way to get an edge magnitude/gradient image. </h2>\n",
    "    \n",
    "**It works by calculating the gradient of image intensity at each pixel within the image. It finds the direction of the largest increase from light to dark and the rate of change in that direction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:27.452254Z",
     "iopub.status.busy": "2024-02-12T12:08:27.451893Z",
     "iopub.status.idle": "2024-02-12T12:08:28.313595Z",
     "shell.execute_reply": "2024-02-12T12:08:28.312715Z",
     "shell.execute_reply.started": "2024-02-12T12:08:27.452218Z"
    }
   },
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.filters import sobel\n",
    "from skimage.filters import sobel_h\n",
    "\n",
    "plt.figure(1,figsize=(20,15))\n",
    "cmap=\"YlGnBu\"\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(sobel(img[:,:,2]),cmap=cmap)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(sobel_h(img[:,:,1]), cmap=cmap)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:28.315799Z",
     "iopub.status.busy": "2024-02-12T12:08:28.315469Z",
     "iopub.status.idle": "2024-02-12T12:08:28.670608Z",
     "shell.execute_reply": "2024-02-12T12:08:28.669713Z",
     "shell.execute_reply.started": "2024-02-12T12:08:28.315767Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(3)\n",
    "pca.fit(matrix)\n",
    "img_pca = pca.transform(matrix)\n",
    "img_pca = np.reshape(img_pca, (dims[0], dims[1], dims[2]))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_pca[:,:,1], cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:28.672249Z",
     "iopub.status.busy": "2024-02-12T12:08:28.671863Z",
     "iopub.status.idle": "2024-02-12T12:08:34.284934Z",
     "shell.execute_reply": "2024-02-12T12:08:34.284097Z",
     "shell.execute_reply.started": "2024-02-12T12:08:28.672213Z"
    }
   },
   "outputs": [],
   "source": [
    "main='/Users/tushar/Documents/FINAL YEAR PROJECT/data/train'\n",
    "\n",
    "data=dict()\n",
    "\n",
    "for i in os.listdir(main):\n",
    "    sub_dir=os.path.join(main,i)\n",
    "    count=len(os.listdir(sub_dir))\n",
    "    data[i]=count\n",
    "    \n",
    "  \n",
    "keys = data.keys()\n",
    "values = data.values()\n",
    "\n",
    "colors=[\"red\" if x<= 150 else \"green\" for x in values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "y_pos=np.arange(len(values))\n",
    "plt.barh(y_pos,values,align='center',color=colors)\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(v+1.4, i-0.25, str(v), color=colors[i])\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(keys)\n",
    "ax.set_xlabel('Images',fontsize=16)\n",
    "plt.xticks(color='black',fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T07:55:30.496241Z",
     "iopub.status.busy": "2021-05-30T07:55:30.495891Z",
     "iopub.status.idle": "2021-05-30T07:55:30.500117Z",
     "shell.execute_reply": "2021-05-30T07:55:30.499297Z",
     "shell.execute_reply.started": "2021-05-30T07:55:30.496187Z"
    }
   },
   "source": [
    "## Let's visualize our dataset by randomly picking an image from every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:34.286621Z",
     "iopub.status.busy": "2024-02-12T12:08:34.286256Z",
     "iopub.status.idle": "2024-02-12T12:08:38.927177Z",
     "shell.execute_reply": "2024-02-12T12:08:38.925969Z",
     "shell.execute_reply.started": "2024-02-12T12:08:34.286583Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_folder = \"/Users/tushar/Documents/FINAL YEAR PROJECT/data/train\"\n",
    "images = []\n",
    "\n",
    "for food_folder in sorted(os.listdir(train_folder)):\n",
    "    food_items = os.listdir(train_folder + '/' + food_folder)\n",
    "    food_selected = np.random.choice(food_items)\n",
    "    images.append(os.path.join(train_folder,food_folder,food_selected))\n",
    "                                     \n",
    "fig=plt.figure(1, figsize=(25, 25))\n",
    "\n",
    "for subplot,image_ in enumerate(images):\n",
    "    category=image_.split('/')[-2]\n",
    "    imgs = plt.imread(image_)\n",
    "    a,b,c=imgs.shape\n",
    "    fig=plt.subplot(5, 4, subplot+1)\n",
    "    fig.set_title(category, pad = 10,size=18)\n",
    "    plt.imshow(imgs)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> MODEL TRAINING </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:38.929086Z",
     "iopub.status.busy": "2024-02-12T12:08:38.928717Z",
     "iopub.status.idle": "2024-02-12T12:08:40.007113Z",
     "shell.execute_reply": "2024-02-12T12:08:40.006260Z",
     "shell.execute_reply.started": "2024-02-12T12:08:38.929049Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "n_classes = 20\n",
    "batch_size = 30\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "train_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/train'\n",
    "\n",
    "# Data Augmentation with ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=40,  # Increased rotation range\n",
    "    width_shift_range=0.2,  # Added width shift\n",
    "    height_shift_range=0.2,  # Added height shift\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/val'\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:40.008457Z",
     "iopub.status.busy": "2024-02-12T12:08:40.008203Z",
     "iopub.status.idle": "2024-02-12T12:08:40.014312Z",
     "shell.execute_reply": "2024-02-12T12:08:40.013393Z",
     "shell.execute_reply.started": "2024-02-12T12:08:40.008430Z"
    }
   },
   "outputs": [],
   "source": [
    "class_map = train_generator.class_indices\n",
    "class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:02:58.333421Z",
     "iopub.status.busy": "2021-05-30T08:02:58.333074Z",
     "iopub.status.idle": "2021-05-30T08:02:58.337311Z",
     "shell.execute_reply": "2021-05-30T08:02:58.336226Z",
     "shell.execute_reply.started": "2021-05-30T08:02:58.333394Z"
    }
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T16:56:32.64429Z",
     "iopub.status.busy": "2021-05-30T16:56:32.643879Z",
     "iopub.status.idle": "2021-05-30T16:56:32.649002Z",
     "shell.execute_reply": "2021-05-30T16:56:32.648019Z",
     "shell.execute_reply.started": "2021-05-30T16:56:32.644255Z"
    }
   },
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T12:08:40.015955Z",
     "iopub.status.busy": "2024-02-12T12:08:40.015617Z",
     "iopub.status.idle": "2024-02-12T21:48:35.715494Z",
     "shell.execute_reply": "2024-02-12T21:48:35.714603Z",
     "shell.execute_reply.started": "2024-02-12T12:08:40.015912Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "nb_train_samples = 15000 \n",
    "nb_validation_samples = 2500\n",
    "\n",
    "# Load MobileNetV2 with pre-trained weights\n",
    "mobilenet = MobileNetV2(weights='imagenet', include_top=False)\n",
    "\n",
    "# Fine-tune the last few layers of MobileNetV2\n",
    "for layer in mobilenet.layers[:-50]:  # Fine-tune more layers\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Add your custom layers for classification\n",
    "x = mobilenet.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer='l2')(x)  # Increased units and added L2 regularization\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=mobilenet.input, outputs=predictions)\n",
    "\n",
    "# Implement Learning Rate Scheduler\n",
    "def lr_scheduler(epoch):\n",
    "    initial_lr = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Compile the model with a lower initial learning rate\n",
    "model.compile(optimizer=SGD(lr=0.0005, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set up callbacks\n",
    "checkpointer = ModelCheckpoint(filepath='v3_mobilenet', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('history_v3_mobilenet.log')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=len(train_generator),\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=len(val_generator),\n",
    "                              epochs=100,\n",
    "                              verbose=1,\n",
    "                              callbacks=[csv_logger, checkpointer, lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:48:35.717557Z",
     "iopub.status.busy": "2024-02-12T21:48:35.717183Z",
     "iopub.status.idle": "2024-02-12T21:48:36.058537Z",
     "shell.execute_reply": "2024-02-12T21:48:36.057618Z",
     "shell.execute_reply.started": "2024-02-12T21:48:35.717518Z"
    }
   },
   "outputs": [],
   "source": [
    " model.save('model_v3_mobilenet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:48:36.060840Z",
     "iopub.status.busy": "2024-02-12T21:48:36.060468Z",
     "iopub.status.idle": "2024-02-12T21:48:36.499880Z",
     "shell.execute_reply": "2024-02-12T21:48:36.499065Z",
     "shell.execute_reply.started": "2024-02-12T21:48:36.060807Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    \n",
    "    plt.plot(history.history['accuracy'],label='train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('Accuracy_v3_mobilenet')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    \n",
    "    plt.plot(history.history['loss'],label=\"train loss\")\n",
    "    plt.plot(history.history['val_loss'],label=\"validation loss\")\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('Loss_v3_mobilenet')\n",
    "    plt.show()\n",
    "    \n",
    "plot_accuracy(history)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> PREDICTIONS </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:48:36.501272Z",
     "iopub.status.busy": "2024-02-12T21:48:36.500978Z",
     "iopub.status.idle": "2024-02-12T21:48:37.721608Z",
     "shell.execute_reply": "2024-02-12T21:48:37.720708Z",
     "shell.execute_reply.started": "2024-02-12T21:48:36.501244Z"
    }
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "path_to_model='./model_v3_mobilenet.h5'\n",
    "print(\"Loading the model..\")\n",
    "model = load_model(path_to_model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:48:37.723314Z",
     "iopub.status.busy": "2024-02-12T21:48:37.722922Z",
     "iopub.status.idle": "2024-02-12T21:48:38.055506Z",
     "shell.execute_reply": "2024-02-12T21:48:38.054629Z",
     "shell.execute_reply.started": "2024-02-12T21:48:37.723273Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:48:38.057312Z",
     "iopub.status.busy": "2024-02-12T21:48:38.056928Z",
     "iopub.status.idle": "2024-02-12T21:49:05.922358Z",
     "shell.execute_reply": "2024-02-12T21:49:05.921445Z",
     "shell.execute_reply.started": "2024-02-12T21:48:38.057273Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "\n",
    "print(\"Test Accuracy: {:.3f}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict single image or predict all images from a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3> Single image prediction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:49:05.926034Z",
     "iopub.status.busy": "2024-02-12T21:49:05.925732Z",
     "iopub.status.idle": "2024-02-12T21:49:05.942021Z",
     "shell.execute_reply": "2024-02-12T21:49:05.941107Z",
     "shell.execute_reply.started": "2024-02-12T21:49:05.926002Z"
    }
   },
   "outputs": [],
   "source": [
    "category={\n",
    "    0: ['apple_pie','Apple Pie'], 1: ['cannoli','Cannoli'], 2: ['chicken_curry','Chicken Curry'],\n",
    "    3: ['chocolate_cake','Chocolate Cake'], 4: ['cup_cake','Cup Cake'], 5: ['donuts','Donuts'],\n",
    "    6: ['dumplings','Dumplings'], 7: ['french_fries','French Fries'], 8: ['fried_rice','Fried Rice'], 9: ['hamburger','Hamburger'],\n",
    "    10: ['hot_and_sour_soup','Hot and Sour Soup'], 11: ['hot_dog','Hot Dog'], 12: ['ice_cream','Ice Cream'],\n",
    "    13: ['nachos','Nachos'], 14: ['omlette','Omlette'], 15: ['pizza','Pizza'],\n",
    "    16: ['ramen','Ramen'], 17: ['samosa','Samosa'], 18: ['spring_rolls','Spring Rolls'], 19: ['waffles','Waffles']\n",
    "}\n",
    "\n",
    "def predict_image(filename,model):\n",
    "    img_ = image.load_img(filename, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img_)\n",
    "    img_processed = np.expand_dims(img_array, axis=0) \n",
    "    img_processed /= 255.   \n",
    "    \n",
    "    prediction = model.predict(img_processed)\n",
    "    \n",
    "    index = np.argmax(prediction)\n",
    "    \n",
    "    plt.title(\"Prediction - {}\".format(category[index][1]))\n",
    "    plt.imshow(img_array)\n",
    "    \n",
    "def predict_dir(filedir,model):\n",
    "    cols=5\n",
    "    pos=0\n",
    "    images=[]\n",
    "    total_images=len(os.listdir(filedir))\n",
    "    rows=total_images//cols + 1\n",
    "    \n",
    "    true=filedir.split('/')[-1]\n",
    "    \n",
    "    fig=plt.figure(1, figsize=(25, 25))\n",
    "    \n",
    "    for i in sorted(os.listdir(filedir)):\n",
    "        images.append(os.path.join(filedir,i))\n",
    "        \n",
    "    for subplot,imggg in enumerate(images):\n",
    "        img_ = image.load_img(imggg, target_size=(299, 299))\n",
    "        img_array = image.img_to_array(img_)\n",
    "        \n",
    "        img_processed = np.expand_dims(img_array, axis=0) \n",
    "\n",
    "        img_processed /= 255.\n",
    "        prediction = model.predict(img_processed)\n",
    "        index = np.argmax(prediction)\n",
    "        \n",
    "        pred=category.get(index)[0]\n",
    "        if pred==true:\n",
    "            pos+=1\n",
    "        \n",
    "        fig=plt.subplot(rows, cols, subplot+1)\n",
    "        fig.set_title(category.get(index)[1], pad = 10,size=18)\n",
    "        plt.imshow(img_array)\n",
    "\n",
    "    acc=pos/total_images\n",
    "    print(\"Accuracy of Test : {:.2f} ({pos}/{total})\".format(acc,pos=pos,total=total_images))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:49:05.944362Z",
     "iopub.status.busy": "2024-02-12T21:49:05.943982Z",
     "iopub.status.idle": "2024-02-12T21:49:07.737093Z",
     "shell.execute_reply": "2024-02-12T21:49:07.736200Z",
     "shell.execute_reply.started": "2024-02-12T21:49:05.944326Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_image('/Users/tushar/Documents/FINAL YEAR PROJECT/data/test/hamburger/1007277.jpg',model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3> Predicting category </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:49:07.738569Z",
     "iopub.status.busy": "2024-02-12T21:49:07.738271Z",
     "iopub.status.idle": "2024-02-12T21:49:25.956739Z",
     "shell.execute_reply": "2024-02-12T21:49:25.955872Z",
     "shell.execute_reply.started": "2024-02-12T21:49:07.738540Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_dir(\"/Users/tushar/Documents/FINAL YEAR PROJECT/data/test/hamburger\",model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T18:20:10.133343Z",
     "iopub.status.busy": "2021-05-31T18:20:10.133029Z",
     "iopub.status.idle": "2021-05-31T18:20:10.136472Z",
     "shell.execute_reply": "2021-05-31T18:20:10.13557Z",
     "shell.execute_reply.started": "2021-05-31T18:20:10.133318Z"
    }
   },
   "source": [
    "## Let's plot a confusion matrix for all the food items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:49:25.958251Z",
     "iopub.status.busy": "2024-02-12T21:49:25.957923Z",
     "iopub.status.idle": "2024-02-12T21:49:25.970006Z",
     "shell.execute_reply": "2024-02-12T21:49:25.969237Z",
     "shell.execute_reply.started": "2024-02-12T21:49:25.958220Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "def labels_confusion_matrix():\n",
    "    folder_path=\"/Users/tushar/Documents/FINAL YEAR PROJECT/data/test\"\n",
    "    \n",
    "    mapping={}\n",
    "    for i,j in enumerate(sorted(os.listdir(folder_path))):\n",
    "        mapping[j]=i\n",
    "    \n",
    "    files=[]\n",
    "    real=[]\n",
    "    predicted=[]\n",
    "\n",
    "    for i in os.listdir(folder_path):\n",
    "        \n",
    "        true=os.path.join(folder_path,i)\n",
    "        true=true.split('/')[-1]\n",
    "        true=mapping[true]\n",
    "        \n",
    "        for j in os.listdir(os.path.join(folder_path,i)):\n",
    "            \n",
    "            img_ = image.load_img(os.path.join(folder_path,i,j), target_size=(img_height, img_width))\n",
    "            img_array = image.img_to_array(img_)\n",
    "            img_processed = np.expand_dims(img_array, axis=0) \n",
    "            img_processed /= 255.\n",
    "            prediction = model.predict(img_processed)\n",
    "            index = np.argmax(prediction)\n",
    "\n",
    "            predicted.append(index)\n",
    "            real.append(true)\n",
    "            \n",
    "    return (real,predicted)\n",
    "\n",
    "def print_confusion_matrix(real,predicted):\n",
    "\n",
    "    cmap=\"viridis\"\n",
    "    cm_plot_labels = [i for i in range(20)]\n",
    "\n",
    "    cm = confusion_matrix(y_true=real, y_pred=predicted)\n",
    "    df_cm = pd.DataFrame(cm,cm_plot_labels,cm_plot_labels)\n",
    "    sns.set(font_scale=1.1) # for label size\n",
    "    plt.figure(figsize = (15,10))\n",
    "    s=sns.heatmap(df_cm, annot=True,cmap=cmap) # font size\n",
    "#     bottom,top=s.get_ylim()\n",
    "#     s.set_ylim(bottom+0.6,top-0.6)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:49:25.971868Z",
     "iopub.status.busy": "2024-02-12T21:49:25.971324Z",
     "iopub.status.idle": "2024-02-12T21:51:12.252227Z",
     "shell.execute_reply": "2024-02-12T21:51:12.251342Z",
     "shell.execute_reply.started": "2024-02-12T21:49:25.971831Z"
    }
   },
   "outputs": [],
   "source": [
    "y_true,y_pred=labels_confusion_matrix()\n",
    "print_confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:51:12.253713Z",
     "iopub.status.busy": "2024-02-12T21:51:12.253407Z",
     "iopub.status.idle": "2024-02-12T21:52:55.747028Z",
     "shell.execute_reply": "2024-02-12T21:52:55.746297Z",
     "shell.execute_reply.started": "2024-02-12T21:51:12.253682Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "category={\n",
    "    0: ['apple_pie','Apple Pie'], 1: ['cannoli','Cannoli'], 2: ['chicken_curry','Chicken Curry'],\n",
    "    3: ['chocolate_cake','Chocolate Cake'], 4: ['cup_cakes','Cup Cakes'], 5: ['donuts','Donuts'],\n",
    "    6: ['dumplings','Dumplings'], 7: ['french_fries','French Fries'], 8: ['fried_rice','Fried Rice'], 9: ['hamburger','Hamburger'],\n",
    "    10: ['hot_and_sour_soup','Hot and Sour Soup'], 11: ['hot_dog','Hot Dog'], 12: ['ice_cream','Ice Cream'],\n",
    "    13: ['nachos','Nachos'], 14: ['omelette','Omelette'], 15: ['pizza','Pizza'],\n",
    "    16: ['ramen','Ramen'], 17: ['samosa','Samosa'], 18: ['spring_rolls','Spring Rolls'], 19: ['waffles','Waffles']\n",
    "}\n",
    "\n",
    "def load_images_and_labels(data_dir):\n",
    "    images, labels = [], []\n",
    "    for i, category_info in category.items():\n",
    "        category_name = category_info[0]\n",
    "        category_path = os.path.join(data_dir, category_name)\n",
    "        \n",
    "        for img_file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_file)\n",
    "            images.append(img_path)\n",
    "            labels.append(i)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Load images and labels from the testing set\n",
    "test_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/test'\n",
    "test_images, test_labels = load_images_and_labels(test_data_dir)\n",
    "\n",
    "# Binarize the labels\n",
    "labels_bin = label_binarize(test_labels, classes=list(category.keys()))\n",
    "\n",
    "# Initialize an empty array to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Make predictions for each image in the testing set\n",
    "for img_path in test_images:\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_processed = np.expand_dims(img_array, axis=0)\n",
    "    img_processed /= 255.\n",
    "    \n",
    "    prediction = model.predict(img_processed)\n",
    "    predictions.append(prediction.flatten())\n",
    "\n",
    "y_scores = np.array(predictions)\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(category)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(len(category)):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for Food Classification')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:52:55.748649Z",
     "iopub.status.busy": "2024-02-12T21:52:55.748282Z",
     "iopub.status.idle": "2024-02-12T21:52:55.765574Z",
     "shell.execute_reply": "2024-02-12T21:52:55.764854Z",
     "shell.execute_reply.started": "2024-02-12T21:52:55.748610Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <b> MODEL LEARNING VISUALIZATIONS </b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOME HELPER FUNCTIONS WHICH WILL ENABLE US TO VISUALIZE HOW NEURAL NETWORK WORKS AND PERFORMS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:52:55.766856Z",
     "iopub.status.busy": "2024-02-12T21:52:55.766606Z",
     "iopub.status.idle": "2024-02-12T21:52:55.791171Z",
     "shell.execute_reply": "2024-02-12T21:52:55.790265Z",
     "shell.execute_reply.started": "2024-02-12T21:52:55.766832Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_activations(img, model_activations):\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)                    \n",
    "    img = np.expand_dims(img, axis=0)         \n",
    "    img /= 255. \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "    return model_activations.predict(img)\n",
    "\n",
    "def show_activations(activations, layer_names):\n",
    "    \n",
    "    images_per_row = 16\n",
    "\n",
    "    # Now let's display our feature maps\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        # This is the number of features in the feature map\n",
    "        n_features = layer_activation.shape[-1]\n",
    "\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = layer_activation.shape[1]\n",
    "\n",
    "        # We will tile the activation channels in this matrix\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        # We'll tile each filter into this big horizontal grid\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:, :,col * images_per_row + row]\n",
    "                # Post-process the feature to make it visually palatable\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "        # Display the grid\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def activation_conv():\n",
    "    first_convlayer_activation = activations[0]\n",
    "    second_convlayer_activation = activations[3]\n",
    "    third_convlayer_activation = activations[6]\n",
    "    f,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "    ax[0].imshow(first_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "    ax[0].axis('OFF')\n",
    "    ax[0].set_title('Conv2d_1')\n",
    "    ax[1].imshow(second_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "    ax[1].axis('OFF')\n",
    "    ax[1].set_title('Conv2d_2')\n",
    "    ax[2].imshow(third_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "    ax[2].axis('OFF')\n",
    "    ax[2].set_title('Conv2d_3')\n",
    "    \n",
    "    \n",
    "def get_attribution(food):\n",
    "    \n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    \n",
    "    img = image.load_img(food, target_size=(299, 299))\n",
    "    img = image.img_to_array(img) \n",
    "    img /= 255. \n",
    "    f,ax = plt.subplots(1,3, figsize=(15,15))\n",
    "    ax[0].imshow(img)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    model = load_model('./model_v1_inceptionV3.h5')\n",
    "        \n",
    "    preds = model.predict(img)\n",
    "    class_id = np.argmax(preds[0])\n",
    "    ax[0].set_title(\"Input Image\")\n",
    "    class_output = model.output[:, class_id]\n",
    "    last_conv_layer = model.get_layer(\"mixed10\")\n",
    "    \n",
    "    grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "    for i in range(2048):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].set_title(\"Heat map\")\n",
    "    \n",
    "    \n",
    "    act_img = cv2.imread(food)\n",
    "    heatmap = cv2.resize(heatmap, (act_img.shape[1], act_img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed = cv2.addWeighted(act_img, 0.6, heatmap, 0.4, 0)\n",
    "    cv2.imwrite('classactivation.png', superimposed)\n",
    "    img_act = image.load_img('classactivation.png', target_size=(299, 299))\n",
    "    ax[2].imshow(img_act)\n",
    "    ax[2].set_title(\"Class Activation\")\n",
    "    plt.show()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:52:55.792639Z",
     "iopub.status.busy": "2024-02-12T21:52:55.792367Z",
     "iopub.status.idle": "2024-02-12T21:52:55.806646Z",
     "shell.execute_reply": "2024-02-12T21:52:55.805821Z",
     "shell.execute_reply.started": "2024-02-12T21:52:55.792613Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total layers in the model : \",len(model.layers),\"\\n\")\n",
    "\n",
    "# We start with index 1 instead of 0, as input layer is at index 0\n",
    "layers = [layer.output for layer in model.layers[1:11]]\n",
    "# We now initialize a model which takes an input and outputs the above chosen layers\n",
    "activations_output = models.Model(inputs=model.input, outputs=layers)\n",
    "# print(layers)\n",
    "\n",
    "layer_names = []\n",
    "for layer in model.layers[1:11]: \n",
    "    layer_names.append(layer.name)\n",
    "    \n",
    "print(\"First 10 layers which we can visualize are -> \", layer_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>LAYER WISE ACTIVATIONS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:52:55.807863Z",
     "iopub.status.busy": "2024-02-12T21:52:55.807612Z",
     "iopub.status.idle": "2024-02-12T21:52:59.468091Z",
     "shell.execute_reply": "2024-02-12T21:52:59.467235Z",
     "shell.execute_reply.started": "2024-02-12T21:52:55.807839Z"
    }
   },
   "outputs": [],
   "source": [
    "food = '/kaggle/input/tushar/val/val/pizza/1220156.jpg'\n",
    "activations = get_activations(food,activations_output)\n",
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:52:59.469579Z",
     "iopub.status.busy": "2024-02-12T21:52:59.469306Z",
     "iopub.status.idle": "2024-02-12T21:52:59.733140Z",
     "shell.execute_reply": "2024-02-12T21:52:59.732238Z",
     "shell.execute_reply.started": "2024-02-12T21:52:59.469552Z"
    }
   },
   "outputs": [],
   "source": [
    "activation_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time let's visualize some other food item's layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:52:59.734818Z",
     "iopub.status.busy": "2024-02-12T21:52:59.734462Z",
     "iopub.status.idle": "2024-02-12T21:53:03.277470Z",
     "shell.execute_reply": "2024-02-12T21:53:03.276426Z",
     "shell.execute_reply.started": "2024-02-12T21:52:59.734779Z"
    }
   },
   "outputs": [],
   "source": [
    "food = '/kaggle/input/tushar/val/val/pizza/1220156.jpg'\n",
    "activations = get_activations(food,activations_output)\n",
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:53:03.279318Z",
     "iopub.status.busy": "2024-02-12T21:53:03.278921Z",
     "iopub.status.idle": "2024-02-12T21:53:03.588656Z",
     "shell.execute_reply": "2024-02-12T21:53:03.587740Z",
     "shell.execute_reply.started": "2024-02-12T21:53:03.279271Z"
    }
   },
   "outputs": [],
   "source": [
    "activation_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>GENERATING HEATMAPS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T21:53:03.590517Z",
     "iopub.status.busy": "2024-02-12T21:53:03.590133Z",
     "iopub.status.idle": "2024-02-12T21:53:04.261691Z",
     "shell.execute_reply": "2024-02-12T21:53:04.260248Z",
     "shell.execute_reply.started": "2024-02-12T21:53:03.590474Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('/kaggle/input/tushar/val/val/samosa/107871.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-12T21:53:04.262587Z",
     "iopub.status.idle": "2024-02-12T21:53:04.263051Z"
    }
   },
   "outputs": [],
   "source": [
    "pred2=get_attribution('/kaggle/input/tushar/val/val/fried_rice/1084.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-12T21:53:04.264048Z",
     "iopub.status.idle": "2024-02-12T21:53:04.264501Z"
    }
   },
   "outputs": [],
   "source": [
    "pred3=get_attribution('/kaggle/input/tushar/val/val/omelette/1145379.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-12T21:53:04.265585Z",
     "iopub.status.idle": "2024-02-12T21:53:04.266060Z"
    }
   },
   "outputs": [],
   "source": [
    "pred4=get_attribution('/kaggle/input/tushar/val/val/chicken_curry/1110023.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-12T21:53:04.266956Z",
     "iopub.status.idle": "2024-02-12T21:53:04.267457Z"
    }
   },
   "outputs": [],
   "source": [
    "pred5=get_attribution('/kaggle/input/tushar/val/val/apple_pie/123782.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:23:15.389366Z",
     "iopub.status.busy": "2021-05-30T14:23:15.389003Z",
     "iopub.status.idle": "2021-05-30T14:23:15.39501Z",
     "shell.execute_reply": "2021-05-30T14:23:15.393067Z",
     "shell.execute_reply.started": "2021-05-30T14:23:15.389333Z"
    }
   },
   "source": [
    "## Downloading random image from net to predict and generate heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-12T21:53:04.268535Z",
     "iopub.status.idle": "2024-02-12T21:53:04.269028Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget -O download.jpg https://www.cookwithmanali.com/wp-content/uploads/2015/01/Restaurant-Style-Dal-Makhani-Recipe.jpg\n",
    "    \n",
    "model_load = load_model('./model_v1_inceptionV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-12T21:53:04.270126Z",
     "iopub.status.idle": "2024-02-12T21:53:04.270610Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = get_attribution('download.jpg')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1374528,
     "sourceId": 2287227,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4389983,
     "sourceId": 7538979,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30097,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
