{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import models\n",
    "from PIL import Image \n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>IMAGE PROCESSSING</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('/Users/tushar/Documents/FINAL YEAR PROJECT/data/train/pizza/1008104.jpg')\n",
    "dims = np.shape(img)\n",
    "matrix = np.reshape(img, (dims[0] * dims[1], dims[2]))\n",
    "print(np.shape(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "print(\"Image shape -> \",dims[:2])\n",
    "print(\"Color channels -> \",dims[2])\n",
    "print(\"Min color depth : {}, Max color depth {}\".format(np.min(img),np.max(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "n_vals=[2,4,6,8]\n",
    "plt.figure(1, figsize=(12, 8))\n",
    "\n",
    "for subplot,n in enumerate(n_vals):\n",
    "    kmeans=cluster.KMeans(n)\n",
    "    clustered = kmeans.fit_predict(matrix)\n",
    "    dims = np.shape(img)\n",
    "    clustered_img = np.reshape(clustered, (dims[0], dims[1]))\n",
    "    plt.subplot(2,2, subplot+1)\n",
    "    plt.title(\"n = {}\".format(n), pad = 10,size=18)\n",
    "    plt.imshow(clustered_img)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnorm = np.zeros_like(matrix, dtype=np.float32)\n",
    "max_range = np.max(matrix, axis=1)\n",
    "bnorm = matrix / np.vstack((max_range, max_range, max_range)).T\n",
    "bnorm_img = np.reshape(bnorm, (dims[0],dims[1],dims[2]))\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.imshow(bnorm_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h2> Sobel filter is a basic way to get an edge magnitude/gradient image. </h2>\n",
    "    \n",
    "**It works by calculating the gradient of image intensity at each pixel within the image. It finds the direction of the largest increase from light to dark and the rate of change in that direction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from skimage.filters import sobel\n",
    "from skimage.filters import sobel_h\n",
    "\n",
    "plt.figure(1,figsize=(20,15))\n",
    "cmap=\"YlGnBu\"\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(img)\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(sobel(img[:,:,2]),cmap=cmap)\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(sobel_h(img[:,:,1]), cmap=cmap)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(3)\n",
    "pca.fit(matrix)\n",
    "img_pca = pca.transform(matrix)\n",
    "img_pca = np.reshape(img_pca, (dims[0], dims[1], dims[2]))\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img_pca[:,:,1], cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main='/Users/tushar/Documents/FINAL YEAR PROJECT/data/train' # write your dataset directory train folder path\n",
    "\n",
    "data=dict()\n",
    "\n",
    "for i in os.listdir(main):\n",
    "    sub_dir=os.path.join(main,i)\n",
    "    if os.path.isdir(sub_dir):\n",
    "        count = len([f for f in os.listdir(sub_dir) if not f.startswith('.')])\n",
    "        data[i] = count\n",
    "    # count=len(os.listdir(sub_dir))\n",
    "    # data[i]=count\n",
    "    \n",
    "  \n",
    "keys = data.keys()\n",
    "values = data.values()\n",
    "\n",
    "colors=[\"red\" if x<= 150 else \"green\" for x in values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "y_pos=np.arange(len(values))\n",
    "plt.barh(y_pos,values,align='center',color=colors)\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(v+1.4, i-0.25, str(v), color=colors[i])\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(keys)\n",
    "ax.set_xlabel('Images',fontsize=16)\n",
    "plt.xticks(color='black',fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T07:55:30.496241Z",
     "iopub.status.busy": "2021-05-30T07:55:30.495891Z",
     "iopub.status.idle": "2021-05-30T07:55:30.500117Z",
     "shell.execute_reply": "2021-05-30T07:55:30.499297Z",
     "shell.execute_reply.started": "2021-05-30T07:55:30.496187Z"
    }
   },
   "source": [
    "## Let's visualize our dataset by randomly picking an image from every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_folder = \"/Users/tushar/Documents/FINAL YEAR PROJECT/data/train\"\n",
    "images = []\n",
    "\n",
    "for food_folder in sorted(os.listdir(train_folder)):\n",
    "    item_path = os.path.join(train_folder, food_folder)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(item_path):\n",
    "        food_items = os.listdir(item_path)\n",
    "        \n",
    "        # Filter out non-image files like .DS_Store\n",
    "        food_items = [item for item in food_items if item.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        if food_items:\n",
    "            food_selected = np.random.choice(food_items)\n",
    "            images.append(os.path.join(train_folder, food_folder, food_selected))\n",
    "\n",
    "    # food_items = os.listdir(train_folder + \"/\" + food_folder)\n",
    "    # food_selected = np.random.choice(food_items)\n",
    "    # images.append(os.path.join(train_folder , food_folder , food_selected))\n",
    "                                     \n",
    "fig=plt.figure(1, figsize=(25, 25))\n",
    "\n",
    "for subplot,image_ in enumerate(images):\n",
    "    category=image_.split('/')[-2]\n",
    "    imgs = plt.imread(image_)\n",
    "    a,b,c=imgs.shape\n",
    "    fig=plt.subplot(5, 4, subplot+1)\n",
    "    fig.set_title(category, pad = 10,size=18)\n",
    "    plt.imshow(imgs)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> MODEL TRAINING </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 20\n",
    "batch_size = 40\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "train_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/train'\n",
    "\n",
    "# Data Augmentation with ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/val'\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = train_generator.class_indices\n",
    "class_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T08:02:58.333421Z",
     "iopub.status.busy": "2021-05-30T08:02:58.333074Z",
     "iopub.status.idle": "2021-05-30T08:02:58.337311Z",
     "shell.execute_reply": "2021-05-30T08:02:58.336226Z",
     "shell.execute_reply.started": "2021-05-30T08:02:58.333394Z"
    }
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T16:56:32.64429Z",
     "iopub.status.busy": "2021-05-30T16:56:32.643879Z",
     "iopub.status.idle": "2021-05-30T16:56:32.649002Z",
     "shell.execute_reply": "2021-05-30T16:56:32.648019Z",
     "shell.execute_reply.started": "2021-05-30T16:56:32.644255Z"
    }
   },
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T05:14:50.949415Z",
     "iopub.status.busy": "2024-02-04T05:14:50.949132Z",
     "iopub.status.idle": "2024-02-04T15:02:45.262852Z",
     "shell.execute_reply": "2024-02-04T15:02:45.261729Z",
     "shell.execute_reply.started": "2024-02-04T05:14:50.949387Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "# from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "# from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "nb_train_samples = 15000 \n",
    "nb_validation_samples = 2500\n",
    "\n",
    "inception = InceptionV3(weights='imagenet', include_top=False)\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "predictions = Dense(n_classes,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=predictions)\n",
    "model.compile(optimizer=RMSprop(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='v1_inceptionV3', verbose=1, save_best_only=True)\n",
    "csv_logger = CSVLogger('history_v1_inceptionV3.log')\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = nb_train_samples // batch_size,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    callbacks=[csv_logger, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T15:02:45.264815Z",
     "iopub.status.busy": "2024-02-04T15:02:45.264499Z",
     "iopub.status.idle": "2024-02-04T15:02:46.055926Z",
     "shell.execute_reply": "2024-02-04T15:02:46.055027Z",
     "shell.execute_reply.started": "2024-02-04T15:02:45.264776Z"
    }
   },
   "outputs": [],
   "source": [
    " model.save('model_v1_inceptionV3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-04T15:02:46.058409Z",
     "iopub.status.busy": "2024-02-04T15:02:46.058120Z",
     "iopub.status.idle": "2024-02-04T15:02:46.521112Z",
     "shell.execute_reply": "2024-02-04T15:02:46.520233Z",
     "shell.execute_reply.started": "2024-02-04T15:02:46.058380Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    \n",
    "    plt.plot(history.history['accuracy'],label='train accuracy')\n",
    "    plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('Accuracy_v1_inceptionV3')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(history):\n",
    "    \n",
    "    plt.plot(history.history['loss'],label=\"train loss\")\n",
    "    plt.plot(history.history['val_loss'],label=\"validation loss\")\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('Loss_v1_inceptionV3')\n",
    "    plt.show()\n",
    "    \n",
    "plot_accuracy(history)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> PREDICTIONS </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "path_to_model='./model_v1_inceptionV3.h5'\n",
    "print(\"Loading the model..\")\n",
    "model = load_model(path_to_model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/test'\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator)\n",
    "\n",
    "print(\"Test Accuracy: {:.3f}\".format(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict single image or predict all images from a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3> Single image prediction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "category={\n",
    "    0: ['apple_pie','Apple Pie'], 1: ['cannoli','Cannoli'], 2: ['chicken_curry','Chicken Curry'],\n",
    "    3: ['chocolate_cake','Chocolate Cake'], 4: ['cup_cake','Cup Cake'], 5: ['donuts','Donuts'],\n",
    "    6: ['dumplings','Dumplings'], 7: ['french_fries','French Fries'], 8: ['fried_rice','Fried Rice'], 9: ['hamburger','Hamburger'],\n",
    "    10: ['hot_and_sour_soup','Hot and Sour Soup'], 11: ['hot_dog','Hot Dog'], 12: ['ice_cream','Ice Cream'],\n",
    "    13: ['nachos','Nachos'], 14: ['omlette','Omlette'], 15: ['pizza','Pizza'],\n",
    "    16: ['ramen','Ramen'], 17: ['samosa','Samosa'], 18: ['spring_rolls','Spring Rolls'], 19: ['waffles','Waffles']\n",
    "}\n",
    "calories = {\n",
    "    0: 237,  # Apple Pie\n",
    "    1: 267,  # Cannoli\n",
    "    2: 220,  # Chicken Curry\n",
    "    3: 350,  # Chocolate Cake\n",
    "    4: 250,  # Cup Cake\n",
    "    5: 195,  # Donuts\n",
    "    6: 41,   # Dumplings\n",
    "    7: 312,  # French Fries\n",
    "    8: 333,  # Fried Rice\n",
    "    9: 250,  # Hamburger\n",
    "    10: 95,  # Hot and Sour Soup\n",
    "    11: 290,  # Hot Dog\n",
    "    12: 137,  # Ice Cream\n",
    "    13: 300,  # Nachos\n",
    "    14: 154,  # Omlette\n",
    "    15: 285,  # Pizza\n",
    "    16: 436,  # Ramen\n",
    "    17: 100,  # Samosa\n",
    "    18: 100,  # Spring Rolls\n",
    "    19: 82    # Waffles\n",
    "}\n",
    "\n",
    "def predict_image(filename,model):\n",
    "    img_ = image.load_img(filename, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img_)\n",
    "    img_processed = np.expand_dims(img_array, axis=0)\n",
    "    img_processed /= 255.\n",
    "\n",
    "    prediction = model.predict(img_processed)\n",
    "\n",
    "    index = np.argmax(prediction)\n",
    "\n",
    "    plt.title(\"Prediction - {}\".format(category[index][1]))\n",
    "    plt.imshow(img_array)\n",
    "    print(\"Food Category - \",category[index][1],\" Calories - \",calories[index])\n",
    "\n",
    "def predict_dir(filedir,model):\n",
    "    cols=5\n",
    "    pos=0\n",
    "    images=[]\n",
    "    total_images=len(os.listdir(filedir))\n",
    "    rows=total_images//cols + 1\n",
    "\n",
    "    true=filedir.split('/')[-1]\n",
    "\n",
    "    fig=plt.figure(1, figsize=(25, 25))\n",
    "\n",
    "    for i in sorted(os.listdir(filedir)):\n",
    "        images.append(os.path.join(filedir,i))\n",
    "\n",
    "    for subplot,imggg in enumerate(images):\n",
    "        img_ = image.load_img(imggg, target_size=(299, 299))\n",
    "        img_array = image.img_to_array(img_)\n",
    "\n",
    "        img_processed = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        img_processed /= 255.\n",
    "        prediction = model.predict(img_processed)\n",
    "        index = np.argmax(prediction)\n",
    "\n",
    "        pred=category.get(index)[0]\n",
    "        if pred==true:\n",
    "            pos+=1\n",
    "\n",
    "        fig=plt.subplot(rows, cols, subplot+1)\n",
    "        fig.set_title(category.get(index)[1], pad = 10,size=18)\n",
    "        plt.imshow(img_array)\n",
    "\n",
    "    acc=pos/total_images\n",
    "    print(\"Accuracy of Test : {:.2f} ({pos}/{total})\".format(acc,pos=pos,total=total_images))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image('/Users/tushar/Documents/FINAL YEAR PROJECT/100 Epoch/waffle-test.jpeg',model) #location of test image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3> Predicting category </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dir(\"/Users/tushar/Documents/FINAL YEAR PROJECT/data/test/ice_cream\",model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T18:20:10.133343Z",
     "iopub.status.busy": "2021-05-31T18:20:10.133029Z",
     "iopub.status.idle": "2021-05-31T18:20:10.136472Z",
     "shell.execute_reply": "2021-05-31T18:20:10.13557Z",
     "shell.execute_reply.started": "2021-05-31T18:20:10.133318Z"
    }
   },
   "source": [
    "## Let's plot a confusion matrix for all the food items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "def labels_confusion_matrix():\n",
    "    folder_path=\"/Users/tushar/Documents/FINAL YEAR PROJECT/data/test\"\n",
    "    \n",
    "    mapping={}\n",
    "    for i,j in enumerate(sorted(os.listdir(folder_path))):\n",
    "        mapping[j]=i\n",
    "    \n",
    "    files=[]\n",
    "    real=[]\n",
    "    predicted=[]\n",
    "\n",
    "    for i in os.listdir(folder_path):\n",
    "        if i == '.DS_Store':  # Skip .DS_Store file\n",
    "            continue\n",
    "        true=os.path.join(folder_path,i)\n",
    "        true=true.split('/')[-1]\n",
    "        true=mapping[true]\n",
    "        \n",
    "        for j in os.listdir(os.path.join(folder_path,i)):\n",
    "            if j == '.DS_Store':  # Skip .DS_Store file\n",
    "                continue\n",
    "            img_ = image.load_img(os.path.join(folder_path,i,j), target_size=(img_height, img_width))\n",
    "            img_array = image.img_to_array(img_)\n",
    "            img_processed = np.expand_dims(img_array, axis=0) \n",
    "            img_processed /= 255.\n",
    "            prediction = model.predict(img_processed)\n",
    "            index = np.argmax(prediction)\n",
    "\n",
    "            predicted.append(index)\n",
    "            real.append(true)\n",
    "            \n",
    "    return (real,predicted)\n",
    "\n",
    "# def print_confusion_matrix(real,predicted):\n",
    "\n",
    "#     cmap=\"viridis\"\n",
    "#     cm_plot_labels = [i for i in range(20)]\n",
    "\n",
    "#     cm = confusion_matrix(y_true=real, y_pred=predicted)\n",
    "#     df_cm = pd.DataFrame(cm,cm_plot_labels,cm_plot_labels)\n",
    "#     sns.set(font_scale=1.1) # for label size\n",
    "#     plt.figure(figsize = (15,10))\n",
    "#     s=sns.heatmap(df_cm, annot=True,cmap=cmap) # font size\n",
    "# #     bottom,top=s.get_ylim()\n",
    "# #     s.set_ylim(bottom+0.6,top-0.6)\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.savefig('confusion_matrix.png')\n",
    "#     plt.show()\n",
    "def print_confusion_matrix(real, predicted):\n",
    "    cmap = \"viridis\"\n",
    "    cm = confusion_matrix(y_true=real, y_pred=predicted)\n",
    "\n",
    "    # Get the unique labels from the true values or predicted values, whichever has more classes\n",
    "    classes = max(max(real), max(predicted)) + 1\n",
    "\n",
    "    cm_plot_labels = [i for i in range(classes)]\n",
    "\n",
    "    # Create the DataFrame with the correct labels\n",
    "    df_cm = pd.DataFrame(cm, index=cm_plot_labels, columns=cm_plot_labels)\n",
    "\n",
    "    sns.set(font_scale=1.1)  # for label size\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    s = sns.heatmap(df_cm, annot=True, cmap=cmap)  # font size\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true,y_pred=labels_confusion_matrix()\n",
    "print_confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "category={\n",
    "    0: ['apple_pie','Apple Pie'], 1: ['cannoli','Cannoli'], 2: ['chicken_curry','Chicken Curry'],\n",
    "    3: ['chocolate_cake','Chocolate Cake'], 4: ['cup_cakes','Cup Cakes'], 5: ['donuts','Donuts'],\n",
    "    6: ['dumplings','Dumplings'], 7: ['french_fries','French Fries'], 8: ['fried_rice','Fried Rice'], 9: ['hamburger','Hamburger'],\n",
    "    10: ['hot_and_sour_soup','Hot and Sour Soup'], 11: ['hot_dog','Hot Dog'], 12: ['ice_cream','Ice Cream'],\n",
    "    13: ['nachos','Nachos'], 14: ['omelette','Omelette'], 15: ['pizza','Pizza'],\n",
    "    16: ['ramen','Ramen'], 17: ['samosa','Samosa'], 18: ['spring_rolls','Spring Rolls'], 19: ['waffles','Waffles']\n",
    "}\n",
    "\n",
    "def load_images_and_labels(data_dir):\n",
    "    images, labels = [], []\n",
    "    for i, category_info in category.items():\n",
    "        category_name = category_info[0]\n",
    "        category_path = os.path.join(data_dir, category_name)\n",
    "        \n",
    "        for img_file in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_file)\n",
    "            images.append(img_path)\n",
    "            labels.append(i)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Load images and labels from the testing set\n",
    "test_data_dir = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/test'\n",
    "test_images, test_labels = load_images_and_labels(test_data_dir)\n",
    "\n",
    "# Binarize the labels\n",
    "labels_bin = label_binarize(test_labels, classes=list(category.keys()))\n",
    "\n",
    "# Initialize an empty array to store predictions\n",
    "predictions = []\n",
    "\n",
    "# Make predictions for each image in the testing set\n",
    "for img_path in test_images:\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_processed = np.expand_dims(img_array, axis=0)\n",
    "    img_processed /= 255.\n",
    "    \n",
    "    prediction = model.predict(img_processed)\n",
    "    predictions.append(prediction.flatten())\n",
    "\n",
    "y_scores = np.array(predictions)\n",
    "\n",
    "# Compute ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(category)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(labels_bin[:, i], y_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(len(category)):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('AUC-ROC Curve for Food Classification')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <b> MODEL LEARNING VISUALIZATIONS </b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(img, model_activations):\n",
    "    img = image.load_img(img, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)                    \n",
    "    img = np.expand_dims(img, axis=0)         \n",
    "    img /= 255. \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "    return model_activations.predict(img)\n",
    "\n",
    "def show_activations(activations, layer_names):\n",
    "    \n",
    "    images_per_row = 16\n",
    "\n",
    "    # Now let's display our feature maps\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        # This is the number of features in the feature map\n",
    "        n_features = layer_activation.shape[-1]\n",
    "\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = layer_activation.shape[1]\n",
    "\n",
    "        # We will tile the activation channels in this matrix\n",
    "        n_cols = n_features // images_per_row\n",
    "        display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "        # We'll tile each filter into this big horizontal grid\n",
    "        for col in range(n_cols):\n",
    "            for row in range(images_per_row):\n",
    "                channel_image = layer_activation[0,:, :,col * images_per_row + row]\n",
    "                # Post-process the feature to make it visually palatable\n",
    "                channel_image -= channel_image.mean()\n",
    "                channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                display_grid[col * size : (col + 1) * size,row * size : (row + 1) * size] = channel_image\n",
    "\n",
    "        # Display the grid\n",
    "        scale = 1. / size\n",
    "        plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def activation_conv():\n",
    "    first_convlayer_activation = activations[0]\n",
    "    second_convlayer_activation = activations[3]\n",
    "    third_convlayer_activation = activations[6]\n",
    "    f,ax = plt.subplots(1,3, figsize=(10,10))\n",
    "    ax[0].imshow(first_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "    ax[0].axis('OFF')\n",
    "    ax[0].set_title('Conv2d_1')\n",
    "    ax[1].imshow(second_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "    ax[1].axis('OFF')\n",
    "    ax[1].set_title('Conv2d_2')\n",
    "    ax[2].imshow(third_convlayer_activation[0, :, :, 3], cmap='viridis')\n",
    "    ax[2].axis('OFF')\n",
    "    ax[2].set_title('Conv2d_3')\n",
    "    \n",
    "    \n",
    "def get_attribution(food):\n",
    "    \n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    \n",
    "    img = image.load_img(food, target_size=(299, 299))\n",
    "    img = image.img_to_array(img) \n",
    "    img /= 255. \n",
    "    f,ax = plt.subplots(1,3, figsize=(15,15))\n",
    "    ax[0].imshow(img)\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    model = load_model('./model_v1_inceptionV3.h5')\n",
    "        \n",
    "    preds = model.predict(img)\n",
    "    class_id = np.argmax(preds[0])\n",
    "    ax[0].set_title(\"Input Image\")\n",
    "    class_output = model.output[:, class_id]\n",
    "    last_conv_layer = model.get_layer(\"mixed10\")\n",
    "    \n",
    "    grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value = iterate([img])\n",
    "    for i in range(2048):\n",
    "        conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].set_title(\"Heat map\")\n",
    "    \n",
    "    \n",
    "    act_img = cv2.imread(food)\n",
    "    heatmap = cv2.resize(heatmap, (act_img.shape[1], act_img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed = cv2.addWeighted(act_img, 0.6, heatmap, 0.4, 0)\n",
    "    cv2.imwrite('classactivation.png', superimposed)\n",
    "    img_act = image.load_img('classactivation.png', target_size=(299, 299))\n",
    "    ax[2].imshow(img_act)\n",
    "    ax[2].set_title(\"Class Activation\")\n",
    "    plt.show()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL LAYERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total layers in the model : \",len(model.layers),\"\\n\")\n",
    "\n",
    "# We start with index 1 instead of 0, as input layer is at index 0\n",
    "layers = [layer.output for layer in model.layers[1:11]]\n",
    "# We now initialize a model which takes an input and outputs the above chosen layers\n",
    "activations_output = models.Model(inputs=model.input, outputs=layers)\n",
    "# print(layers)\n",
    "\n",
    "layer_names = []\n",
    "for layer in model.layers[1:11]: \n",
    "    layer_names.append(layer.name)\n",
    "    \n",
    "print(\"First 10 layers which we can visualize are -> \", layer_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>LAYER WISE ACTIVATIONS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/pizza/1220156.jpg'\n",
    "activations = get_activations(food,activations_output)\n",
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This time let's visualize some other food item's layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = '/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/pizza/1220156.jpg'\n",
    "activations = get_activations(food,activations_output)\n",
    "show_activations(activations, layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_conv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>GENERATING HEATMAPS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_attribution('/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/samosa/107871.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=get_attribution('/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/fried_rice/1084.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3=get_attribution('/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/omelette/1145379.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4=get_attribution('/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/chicken_curry/1110023.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5=get_attribution('/Users/tushar/Documents/FINAL YEAR PROJECT/data/val/apple_pie/123782.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:23:15.389366Z",
     "iopub.status.busy": "2021-05-30T14:23:15.389003Z",
     "iopub.status.idle": "2021-05-30T14:23:15.39501Z",
     "shell.execute_reply": "2021-05-30T14:23:15.393067Z",
     "shell.execute_reply.started": "2021-05-30T14:23:15.389333Z"
    }
   },
   "source": [
    "## Downloading random image from net to predict and generate heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O download.jpg https://www.cookwithmanali.com/wp-content/uploads/2015/01/Restaurant-Style-Dal-Makhani-Recipe.jpg\n",
    "    \n",
    "model_load = load_model('./model_v1_inceptionV3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_attribution('download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1374528,
     "sourceId": 2287227,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4389983,
     "sourceId": 7538979,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30097,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
